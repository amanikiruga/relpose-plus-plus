{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "751339a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=3\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de568412",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "import os.path as osp\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from pytorch3d.vis.plotly_vis import plot_scene\n",
    "from pytorch3d.renderer import FoVPerspectiveCameras\n",
    "\n",
    "from dataset import CustomDataset\n",
    "from eval import evaluate_coordinate_ascent, evaluate_mst\n",
    "from models import get_model\n",
    "from utils import (\n",
    "    unnormalize_image,\n",
    "    view_color_coded_images_from_path,\n",
    "    view_color_coded_images_from_tensor,\n",
    ")\n",
    "import plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad3bcb5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint ckpt_000800000.pth\n",
      "Missing keys: ['feature_extractor.feature_positional_encoding.pos_table_1']\n",
      "Unexpected keys: []\n"
     ]
    }
   ],
   "source": [
    "model_dir = \"/home/jason/relpose-plus-plus-dev/weights/relposepp\"\n",
    "model, args = get_model(model_dir, num_images=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "935eaaa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = \"../examples/robot/images\"\n",
    "mask_dir = \"../examples/robot/masks\"\n",
    "bboxes = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ada2eb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CustomDataset(\n",
    "    image_dir=image_dir,\n",
    "    mask_dir=mask_dir,\n",
    "    bboxes=bboxes,\n",
    "    mask_images=args.get(\"mask_images\", False),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8bbf25cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "num_frames = dataset.n\n",
    "batch = dataset.get_data(ids=np.arange(num_frames))\n",
    "images = batch[\"image\"].to(device)\n",
    "crop_params = batch[\"crop_params\"].to(device)\n",
    "\n",
    "batched_images, batched_crop_params = images.unsqueeze(0), crop_params.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afe9b16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, hypothesis = evaluate_mst(\n",
    "    model=model,\n",
    "    images=batched_images,\n",
    "    use_all_features=True,\n",
    "    crop_params=batched_crop_params,\n",
    ")\n",
    "R_pred = np.stack(hypothesis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7944b0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    _, _, T_pred = model(images=batched_images, crop_params=batched_crop_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ab769aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78ee233e408b428d996946d69895e9c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    _, hypothesis = evaluate_coordinate_ascent(\n",
    "        model=model,\n",
    "        images=batched_images,\n",
    "        use_all_features=True,\n",
    "        crop_params=batched_crop_params,\n",
    "    )\n",
    "R_final = np.stack(hypothesis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e14d54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotly_scene_visualization(R_pred_mst, R_pred_coord_asc, T_pred):\n",
    "    num_frames = len(R_pred_mst)\n",
    "\n",
    "    scenes = {\n",
    "        \"Initial Predicted Cameras\": {},\n",
    "        \"Final Optimized Cameras\": {},\n",
    "    }\n",
    "\n",
    "    for i in range(num_frames):\n",
    "        scenes[\"Initial Predicted Cameras\"][i] = FoVPerspectiveCameras(\n",
    "            R=R_pred_mst[i, None], T=T_pred[i, None]\n",
    "        )\n",
    "        scenes[\"Final Optimized Cameras\"][i] = FoVPerspectiveCameras(\n",
    "            R=R_pred_coord_asc[i, None], T=T_pred[i, None]\n",
    "        )\n",
    "\n",
    "    fig = plot_scene(\n",
    "        scenes,\n",
    "        camera_scale=0.03,\n",
    "        ncols=2,\n",
    "    )\n",
    "    fig.update_scenes(aspectmode=\"data\")\n",
    "\n",
    "    cmap = plt.get_cmap(\"hsv\")\n",
    "    for i in range(num_frames):\n",
    "        fig.data[i].line.color = matplotlib.colors.to_hex(cmap(i / (num_frames)))\n",
    "        fig.data[i + num_frames].line.color = matplotlib.colors.to_hex(\n",
    "            cmap(i / (num_frames))\n",
    "        )\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7a3d08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plotly_scene_visualization(R_pred, R_final, T_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d298ff28",
   "metadata": {},
   "outputs": [],
   "source": [
    "html_plot = plotly.io.to_html(fig, full_html=False, include_plotlyjs=\"cdn\")\n",
    "\n",
    "# with open(\"template.html\", \"w\") as f:\n",
    "#     f.write(html_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bbf86530",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import base64\n",
    "\n",
    "#     s = io.BytesIO()\n",
    "#     plt.plot(list(range(100)))\n",
    "#     plt.savefig(s, format='png', bbox_inches=\"tight\")\n",
    "#     plt.close()\n",
    "#     s = base64.b64encode(s.getvalue()).decode(\"utf-8\").replace(\"\\n\", \"\")\n",
    "#     return '<img align=\"left\" src=\"data:image/png;base64,%s\">' % s\n",
    "\n",
    "s = io.BytesIO()\n",
    "view_color_coded_images_from_tensor(images)\n",
    "plt.savefig(s, format=\"png\", bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "image_encoded = base64.b64encode(s.getvalue()).decode(\"utf-8\").replace(\"\\n\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "75c654ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML_TEMPLATE = \"\"\"<html><head><meta charset=\"utf-8\"/></head>\n",
    "<body><img src=\"data:image/png;charset=utf-8;base64,{image_encoded}\"/>\n",
    "{plotly_html}</body></html>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb855e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test.html\", \"w\") as f:\n",
    "    s = HTML_TEMPLATE.format(\n",
    "        image_encoded=image_encoded,\n",
    "        plotly_html=html_plot,\n",
    "    )\n",
    "    f.write(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "89e9ab28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[138, 96, 431, 747],\n",
       " [86, 108, 459, 729],\n",
       " [117, 127, 447, 747],\n",
       " [204, 142, 438, 748],\n",
       " [118, 90, 427, 748],\n",
       " [199, 83, 499, 760],\n",
       " [150, 100, 510, 713],\n",
       " [236, 154, 514, 739]]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.bboxes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
